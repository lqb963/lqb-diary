<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0"
    />
    <title>Audio Waveform Visualization</title>
    <style>
      canvas {
        border: 1px solid black;
      }
    </style>
  </head>
  <body>
    <canvas
      id="waveformCanvas"
      width="800"
      height="200"
    ></canvas>
    <script>
      // 获取 canvas 元素和上下文
      const canvas = document.getElementById('waveformCanvas');
      const ctx = canvas.getContext('2d');

      // 加载音频文件并处理为 ArrayBuffer
      async function loadAudio(url) {
        const response = await fetch(url);
        const arrayBuffer = await response.arrayBuffer();
        return arrayBuffer;
      }

      // 解码音频数据并绘制波形
      async function drawWaveform(url) {
        const audioBuffer = await loadAudio(url);
        const audioContext = new (window.AudioContext ||
          window.webkitAudioContext)();

        // 解码音频数据
        const decodedData = await audioContext.decodeAudioData(audioBuffer);

        // 获取音频数据
        const channelData = decodedData.getChannelData(0); // 获取第一个声道的数据

        // 绘制波形
        const width = canvas.width;
        const height = canvas.height;
        const middle = height / 2;
        const step = Math.ceil(channelData.length / width);

        ctx.clearRect(0, 0, width, height);
        ctx.beginPath();
        ctx.moveTo(0, middle);

        for (let i = 0; i < width; i++) {
          const value = channelData[i * step];
          const y = middle + value * middle; // 将值映射到 canvas 高度
          ctx.lineTo(i, y);
        }

        ctx.strokeStyle = 'black';
        ctx.stroke();
      }

      // 调用函数并传入音频文件的 URL
      drawWaveform('path/to/your/audio/file.mp3'); // 替换为你的音频文件路径
    </script>
  </body>
</html>
